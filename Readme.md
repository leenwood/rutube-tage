Для запуска приложение желательно python 3.11
При запуске запускаем main.py и передаем аргумент console / server
Если передать console тогда все видео из папки инпут и input.csv распарсаться и переложаться в папку output в result.json
Если запустить сервер, тогда по порту localhost:8000 будет доступ к интерфейсу приложения для тэгирование

Зависимости находяться в папке app (requirements.txt)

```bash
python app/main.py server
```

```bash
python app/main.py console
```

____

Логика работы такая что на вход через папку input подается видео, лоигка делиться на два варианта, если http, то тогда title и description передаются через форму, если консольный запуск то тогда в input должен лежать файл input.csv, в котором описаны title и description, а также video_id.

После чего видео разделяется (MediaSplitter) на аудио и видео дорожку, так как мы планировали ещё брать видео, но в дальнейшем пришлось отказаться от этой идеи. Звук скалдывается в папку output/audios/.
После того как видео разделилось, аудиодорожка начинает обрабатываться (TranscriptionSpeech) при помощи whisper в котором идет транскрипция текста, для оптимизации был выбран путь трансккрипции первых 3 минут
После чего транскрипция видео отправляется на обработку (KeywordsExtractor) и получения топ популярных слов исключая стоп слова.
Получившиеяся собранные данные передатся в предсказатель2001, (Predict), из которого возращается проставленные теги которые потом сохраняется и отображаются либо в outpur/result.json, либо на сайте

### PREDICTOR2001

Весь код обучения модели находится в train.ipynb. Мы решили не отходить далеко от бейзлайна, так как другие методы не дали существенного прироста, поэтому решили сосредоточиться на поиске ближайших по вектору эмбедингов.
Алгоритм по поиску ближайших тегов состоит в том, что мы берем эмбединги тегов и эмбединг мета информации (название видео, описание и популярные слова) и ищем ближайшие через FAISS. В данный момент код берет только определенное количество тегов (top_n). 
